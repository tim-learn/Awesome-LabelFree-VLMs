# Unsupervised Domain Transfer

* `arXiv 2022` **[Unsupervised Prompt Learning for Vision-Language Models](https://arxiv.org/pdf/2204.03649)** [![Star](https://img.shields.io/github/stars/tonyhuang2022/UPL.svg?style=social&label=Star)](https://github.com/tonyhuang2022/UPL)
    * Tony Huang, Jack Chu, Fangyun Wei
* `arXiv 2022` **[Improving Zero-Shot Models with Label Distribution Priors](https://arxiv.org/pdf/2212.00784)** [![Star](https://img.shields.io/github/stars/jonkahana/CLIPPR.svg?style=social&label=Star)](https://github.com/jonkahana/CLIPPR)
    * Jonathan Kahana, Niv Cohen, Yedid Hoshen
* `ICLR-2023` **[Masked Unsupervised Self-training for Label-free Image Classification](https://openreview.net/pdf/4727dfde7523443e21ec3f97b19eeba777450c3e.pdf)** [![Star](https://img.shields.io/github/stars/salesforce/MUST.svg?style=social&label=Star)](https://github.com/salesforce/MUST)
    * Junnan Li, Silvio Savarese, Steven CH Hoi
* `ICML-2023` **[A Simple Zero-shot Prompt Weighting Technique to Improve Prompt Ensembling in Text-Image Models](https://arxiv.org/pdf/2302.06235)**
    * James Urquhart Allingham*, Jie Ren*, Michael W Dusenberry, Xiuye Gu, Yin Cui, Dustin Tran, Jeremiah Zhe Liu, Balaji Lakshminarayanan
* `ICML-2023` **[POUF: Prompt-Oriented Unsupervised Fine-tuning for Large Pre-trained Models](https://proceedings.mlr.press/v202/tanwisuth23a/tanwisuth23a.pdf)** [![Star](https://img.shields.io/github/stars/korawat-tanwisuth/POUF.svg?style=social&label=Star)](https://github.com/korawat-tanwisuth/POUF)
    * Korawat Tanwisuth, Shujian Zhang, Huangjie Zheng, Pengcheng He, Mingyuan Zhou
* `PRCV-2023` **[Unsupervised Prototype Adapter for Vision-Language Models](https://arxiv.org/pdf/2308.11507)**
    * Yi Zhang, Ce Zhang, Xueting Hu, Zhihai He
* `NeurIPS-2023` **[Neural Priming for Sample-Efficient Adaptation](https://proceedings.neurips.cc/paper_files/paper/2023/file/cea5bc68b890bffb10f18aaaab2becb1-Paper-Conference.pdf)** [![Star](https://img.shields.io/github/stars/RAIVNLab/neural-priming.svg?style=social&label=Star)](https://github.com/RAIVNLab/neural-priming)
    * Matthew Wallingford, Vivek Ramanujan, Alex Fang, Aditya Kusupati, Roozbeh Mottaghi, Aniruddha Kembhavi, Ludwig Schmidt, Ali Farhadi
* `NeurIPS-2023` **[LaFTer: Label-Free Tuning of Zero-shot Classifier using Language and Unlabeled Image Collections](https://proceedings.neurips.cc/paper_files/paper/2023/file/123a18dfd821c8b440f42a00a27648d6-Paper-Conference.pdf)** [![Star](https://img.shields.io/github/stars/jmiemirza/LaFTer.svg?style=social&label=Star)](https://github.com/jmiemirza/LaFTer)
    * M Jehanzeb Mirza, Leonid Karlinsky, Wei Lin, Mateusz Kozinski, Horst Possegger, Rogerio Feris, Horst Bischof
* `NeurIPS-2023` **[Enhancing CLIP with CLIP: Exploring Pseudolabeling for Limited-Label Prompt Tuning](https://proceedings.neurips.cc/paper_files/paper/2023/file/bf85879363044ca21f7868a3d1b4021c-Paper-Conference.pdf)** [![Star](https://img.shields.io/github/stars/BatsResearch/menghini-neurips23-code.svg?style=social&label=Star)](https://github.com/BatsResearch/menghini-neurips23-code)
    * Cristina Menghini, Andrew Delworth, Stephen H Bach
* `NeurIPS-2023` **[Intra-Modal Proxy Learning for Zero-Shot Visual Categorization with CLIP](https://proceedings.neurips.cc/paper_files/paper/2023/file/50a057e9fe79ffa3f4120fb6fb88071a-Paper-Conference.pdf)**
    * Qi Qian, Yuanhong Xu, Juhua Hu
* `NeurIPS-2023` **[SwapPrompt: Test-Time Prompt Adaptation for Vision-Language Models](https://proceedings.neurips.cc/paper_files/paper/2023/file/cdd0640218a27e9e2c0e52e324e25db0-Paper-Conference.pdf)**
    * Xiaosong Ma, Jie Zhang, Song Guo, Wenchao Xu
* `Internationa Journal of Applied Earth Observation and Geoinformation-2023` **[RS-CLIP: Zero shot remote sensing scene classification via contrastive vision-language supervision](https://www.sciencedirect.com/science/article/pii/S1569843223003217)** [![Star](https://img.shields.io/github/stars/lx709/RS-CLIP.svg?style=social&label=Star)](https://github.com/lx709/RS-CLIP)
    * Xiang Li, Congcong Wen, Yuan Hu, Nan Zhou
* `arXiv 2023` **[Prompt Ensemble Self-training for Open-Vocabulary Domain Adaptation](https://arxiv.org/pdf/2306.16658)**
    * Jiaxing Huang, Jingyi Zhang, Han Qiu, Sheng Jin, Shijian Lu
* `arXiv 2023` **[Improving CLIP Robustness with Knowledge Distillation and Self-Training](https://arxiv.org/pdf/2309.10361)**
    * Clement Laroudie, Andrei Bursuc, Mai Lan Ha, Gianni Franchi
* `WACV-2024` **[ReCLIP: Refine Contrastive Language Image Pre-Training with Source Free Domain Adaptation](https://openaccess.thecvf.com/content/WACV2024/papers/Hu_ReCLIP_Refine_Contrastive_Language_Image_Pre-Training_With_Source_Free_Domain_WACV_2024_paper.pdf)** [![Star](https://img.shields.io/github/stars/michiganleon/ReCLIP_WACV.svg?style=social&label=Star)](https://github.com/michiganleon/ReCLIP_WACV)
    * Xuefeng Hu, Ke Zhang, Lu Xia, Albert Chen, Jiajia Luo, Yuyin Sun, Ken Wang, Nan Qiao, Xiao Zeng, Min Sun, Cheng-Hao Kuo, Ram Nevatia
* `CVPR-2024` **[PromptKD: Unsupervised Prompt Distillation for Vision-Language Models](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_PromptKD_Unsupervised_Prompt_Distillation_for_Vision-Language_Models_CVPR_2024_paper.pdf)** [![Star](https://img.shields.io/github/stars/zhengli97/PromptKD.svg?style=social&label=Star)](https://github.com/zhengli97/PromptKD)
    * Zheng Li, Xiang Li, Xinyi Fu, Xin Zhang, Weiqiang Wang, Shuo Chen, Jian Yang
* `CVPR-2024` **[Label Propagation for Zero-shot Classification with Vision-Language Models](https://openaccess.thecvf.com/content/CVPR2024/papers/Stojni_Label_Propagation_for_Zero-shot_Classification_with_Vision-Language_Models_CVPR_2024_paper.pdf)** [![Star](https://img.shields.io/github/stars/vladan-stojnic/ZLaP.svg?style=social&label=Star)](https://github.com/vladan-stojnic/ZLaP)
    * Vladan Stojnić, Yannis Kalantidis, Giorgos Tolias
* `CVPR-2024` **[Transductive Zero-Shot and Few-Shot CLIP](https://arxiv.org/pdf/2405.18437)** [![Star](https://img.shields.io/github/stars/SegoleneMartin/transductive-CLIP.svg?style=social&label=Star)](https://github.com/SegoleneMartin/transductive-CLIP)
    * Ségolène Martin, Yunshi Huang, Fereshteh Shakeri, Jean-Christophe Pesquet, Ismail Ben Ayed
* `ICML-2024` **[Realistic Unsupervised CLIP Fine-tuning with Universal Entropy Optimization](https://openreview.net/pdf?id=XxCfToC9pJ)** [![Star](https://img.shields.io/github/stars/tim-learn/UEO.svg?style=social&label=Star)](https://github.com/tim-learn/UEO)
    * Jian Liang, Lijun Sheng, Zhengbo Wang, Ran He, Tieniu Tan
* `ICML-2024` **[Candidate Pseudolabel Learning: Enhancing Vision-Language Models by Prompt Tuning with Unlabeled Data](https://arxiv.org/pdf/2406.10502)** [![Star](https://img.shields.io/github/stars/vanillaer/CPL-ICML2024.svg?style=social&label=Star)](https://github.com/vanillaer/CPL-ICML2024)
    * Jiahan Zhang, Qi Wei, Feng Liu, Lei Feng
* `ICML-2024` **[Robust CLIP: Unsupervised Adversarial Fine-Tuning of Vision Embeddings for Robust Large Vision-Language Models](https://arxiv.org/pdf/2402.12336)** [![Star](https://img.shields.io/github/stars/chs20/RobustVLM.svg?style=social&label=Star)](https://github.com/chs20/RobustVLM)
    * Christian Schlarmann, Naman Deep Singh, Francesco Croce, Matthias Hein
* `ECCV-2024` **[Improving Zero-shot Generalization of Learned Prompts via Unsupervised Knowledge Distillation](https://arxiv.org/pdf/2407.03056)** [![Star](https://img.shields.io/github/stars/miccunifi/KDPL.svg?style=social&label=Star)](https://github.com/miccunifi/KDPL)
    * Marco Mistretta, Alberto Baldrati, Marco Bertini, Andrew D Bagdanov
* `ECCV-2024` **[uCAP: An Unsupervised Prompting Method for Vision-Language Models](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/09508.pdf)**
    * A Tuan Nguyen, Kai Sheng Tai, Bor-Chun Chen, Satya Narayan Shukla, Hanchao Yu, Philip Torr, Tai-Peng Tian, Ser-Nam Lim
* `BMVC-2024` **[Noise-Tolerant Few-Shot Unsupervised Adapter for Vision-Language Models](https://arxiv.org/pdf/2309.14928)**
    * Eman Ali, Muhammad Haris Khan
* `NeurIPS-2024` **[Boosting Vision-Language Models with Transduction](https://arxiv.org/pdf/2406.01837)** [![Star](https://img.shields.io/github/stars/MaxZanella/transduction-for-vlms.svg?style=social&label=Star)](https://github.com/MaxZanella/transduction-for-vlms)
    * Maxime Zanella, Benoît Gérin, Ismail Ayed
* `NeurIPS-2024` **[OTTER: Effortless Label Distribution Adaptation of Zero-shot Models](https://arxiv.org/pdf/2404.08461)** [![Star](https://img.shields.io/github/stars/SprocketLab/OTTER.svg?style=social&label=Star)](https://github.com/SprocketLab/OTTER)
    * Changho Shin, Jitian Zhao, Sonia Cromp, Harit Vishwakarma, Frederic Sala
* `arXiv 2024` **[Training-Free Unsupervised Prompt for Vision-Language Models](https://arxiv.org/pdf/2404.16339)**
    * Sifan Long, Linbin Wang, Zhen Zhao, Zichang Tan, Yiming Wu, Shengsheng Wang, Jingdong Wang
* `arXiv 2024` **[Can Language-Guided Unsupervised Adaptation Improve Medical Image Classification Using Unpaired Images and Texts?](https://arxiv.org/pdf/2409.02729)**
    * Umaima Rahman, Raza Imam, Dwarikanath Mahapatra, Boulbaba Ben Amor
* `arXiv 2024` **[Lightweight Unsupervised Federated Learning with Pretrained Vision Language Model](https://arxiv.org/pdf/2404.11046)**
    * Hao Yan, Yuhong Guo
* `arXiv 2024` **[CLIP meets DINO for Tuning Zero-Shot Classifier using Unlabeled Image Collections](https://arxiv.org/pdf/2411.19346)**
    * Mohamed Fazli Imam, Rufael Fedaku Marew, Jameel Hassan, Mustansar Fiaz, Alham Fikri Aji, Hisham Cholakkal
* `arXiv 2024` **[Data-Efficient CLIP-Powered Dual-Branch Networks for Source-Free Unsupervised Domain Adaptation](https://arxiv.org/pdf/2410.15811)**
    * Yongguang Li, Yueqi Cao, Jindong Li, Qi Wang, Shengsheng Wang
* `WACV-2025` **[DPA: Dual Prototypes Alignment for Unsupervised Adaptation of Vision-Language Models](https://arxiv.org/pdf/2408.08855)**
    * Eman Ali, Sathira Silva, Muhammad Haris Khan
* `WACV-2025` **[LATTECLIP: Unsupervised CLIP Fine-Tuning via LMM-Synthetic Texts](https://arxiv.org/pdf/2410.08211)** [![Star](https://img.shields.io/github/stars/astra-vision/LatteCLIP.svg?style=social&label=Star)](https://github.com/astra-vision/LatteCLIP)
    * Anh-Quan Cao, Maximilian Jaritz, Matthieu Guillaumin, Raoul de Charette, Loris Bazzani
* `ICCV-2025` **[FLOSS: Free Lunch in Open-vocabulary Semantic Segmentation](https://arxiv.org/pdf/2504.10487)** [![Star](https://img.shields.io/github/stars/yasserben/FLOSS.svg?style=social&label=Star)](https://github.com/yasserben/FLOSS)
    * Yasser Benigmim, Mohammad Fahes, Tuan-Hung Vu, Andrei Bursuc, Raoul de Charette
* `ICCV-2025` **[Generate, Transduct, Adapt: Iterative Transduction with VLMs](https://arxiv.org/pdf/2501.06031)**
    * Oindrila Saha, Logan Lawrence, Grant Van Horn, Subhransu Maji
* `arXiv 2025` **[OTFusion: Bridging Vision-only and Vision-Language Models via Optimal Transport for Transductive Zero-Shot Learning](https://arxiv.org/pdf/2506.13723)**
    * Qiyu Xu, Wenyang Chen, Zhanxuan Hu, Huafeng Li, Yonghang Tai
