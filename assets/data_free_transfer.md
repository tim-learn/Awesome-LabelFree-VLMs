# Data-Free Transfer

* `ICML-2021` **[Learning Transferable Visual Models From Natural Language Supervision](https://proceedings.mlr.press/v139/radford21a/radford21a.pdf)** [![Star](https://img.shields.io/github/stars/openai/CLIP.svg?style=social&label=Star)](https://github.com/openai/CLIP)
    * Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever
* `ECCV-2022` **[Extract Free Dense Labels from CLIP](https://arxiv.org/pdf/2112.01071)** [![Star](https://img.shields.io/github/stars/chongzhou96/MaskCLIP.svg?style=social&label=Star)](https://github.com/chongzhou96/MaskCLIP)
    * Chong Zhou, Chen Change Loy, Bo Dai
* `NeurIPS-2022` **[ReCo: Retrieve and Co-segment for Zero-shot Transfer](https://arxiv.org/pdf/2206.07045)** [![Star](https://img.shields.io/github/stars/NoelShin/reco.svg?style=social&label=Star)](https://github.com/NoelShin/reco)
    * Gyungin Shin, Weidi Xie, Samuel Albanie
* `AAAI-2023` **[CALIP: Zero-Shot Enhancement of CLIP with Parameter-free Attention](https://arxiv.org/pdf/2209.14169)** [![Star](https://img.shields.io/github/stars/ZiyuGuo99/CALIP.svg?style=social&label=Star)](https://github.com/ZiyuGuo99/CALIP)
    * Ziyu Guo, Renrui Zhang, Longtian Qiu, Xianzheng Ma, Xupeng Miao, Xuming He, Bin Cui
* `ICLR-2023` **[Visual Classification via Description from Large Language Models](https://openreview.net/pdf?id=jlAjNL8z5cs)** [![Star](https://img.shields.io/github/stars/sachit-menon/classify_by_description_release.svg?style=social&label=Star)](https://github.com/sachit-menon/classify_by_description_release)
    * Sachit Menon, Carl Vondrick
* `CVPR-2023` **[Texts as Images in Prompt Tuning for Multi-Label Image Recognition](https://openaccess.thecvf.com/content/CVPR2023/papers/Guo_Texts_as_Images_in_Prompt_Tuning_for_Multi-Label_Image_Recognition_CVPR_2023_paper.pdf)** [![Star](https://img.shields.io/github/stars/guozix/TaI-DPT.svg?style=social&label=Star)](https://github.com/guozix/TaI-DPT)
    * Zixian Guo, Bowen Dong, Zhilong Ji, Jinfeng Bai, Yiwen Guo, Wangmeng Zuo
* `CVPRW-2023` **[Diversity is Definitely Needed: Improving Model-Agnostic Zero-shot Classification via Stable Diffusion](https://openaccess.thecvf.com/content/CVPR2023W/GCV/papers/Shipard_Diversity_Is_Definitely_Needed_Improving_Model-Agnostic_Zero-Shot_Classification_via_Stable_CVPRW_2023_paper.pdf)** [![Star](https://img.shields.io/github/stars/Jordan-HS/Diversity_is_Definitely_Needed.svg?style=social&label=Star)](https://github.com/Jordan-HS/Diversity_is_Definitely_Needed)
    * Jordan Shipard, Arnold Wiliem, Kien Nguyen Thanh, Wei Xiang, Clinton Fookes
* `ICML-2023` **[CHiLS: Zero-Shot Image Classification with Hierarchical Label Sets](https://proceedings.mlr.press/v202/novack23a/novack23a.pdf)** [![Star](https://img.shields.io/github/stars/acmi-lab/CHILS.svg?style=social&label=Star)](https://github.com/acmi-lab/CHILS)
    * Zachary Novack, Julian McAuley, Zachary Chase Lipton, Saurabh Garg
* `ICMLW-2023` **[A ChatGPT Aided Explainable Framework for Zero-Shot Medical Image Diagnosis](https://arxiv.org/pdf/2307.01981)**
    * Jiaxiang Liu, Tianxiang Hu, Yan Zhang, Xiaotang Gai, Yang Feng, Zuozhu Liu
* `ICCV-2023` **[What Does a Platypus Look Like? Generating Customized Prompts for Zero-Shot Image Classification](https://openaccess.thecvf.com/content/ICCV2023/papers/Pratt_What_Does_a_Platypus_Look_Like_Generating_Customized_Prompts_for_ICCV_2023_paper.pdf)** [![Star](https://img.shields.io/github/stars/sarahpratt/CuPL.svg?style=social&label=Star)](https://github.com/sarahpratt/CuPL)
    * Sarah Pratt, Ian Covert, Rosanne Liu, Ali Farhadi
* `ICCV-2023` **[SuS-X: Training-Free Name-Only Transfer of Vision-Language Models](https://openaccess.thecvf.com/content/ICCV2023/papers/Udandarao_SuS-X_Training-Free_Name-Only_Transfer_of_Vision-Language_Models_ICCV_2023_paper.pdf)** [![Star](https://img.shields.io/github/stars/vishaal27/SuS-X.svg?style=social&label=Star)](https://github.com/vishaal27/SuS-X)
    * Vishaal Udandarao, Ankush Gupta, Samuel Albanie
* `ICCV-2023` **[Waffling around for Performance: Visual Classification with Random Words and Broad Concepts](https://openaccess.thecvf.com/content/ICCV2023/papers/Roth_Waffling_Around_for_Performance_Visual_Classification_with_Random_Words_and_ICCV_2023_paper.pdf)** [![Star](https://img.shields.io/github/stars/ExplainableML/WaffleCLIP.svg?style=social&label=Star)](https://github.com/ExplainableML/WaffleCLIP)
    * Karsten Roth*, Jae Myung Kim*, A Koepke, Oriol Vinyals, Cordelia Schmid, Zeynep Akata
* `NeurIPS-2023` **[Neural Priming for Sample-Efficient Adaptation](https://proceedings.neurips.cc/paper_files/paper/2023/file/cea5bc68b890bffb10f18aaaab2becb1-Paper-Conference.pdf)** [![Star](https://img.shields.io/github/stars/RAIVNLab/neural-priming.svg?style=social&label=Star)](https://github.com/RAIVNLab/neural-priming)
    * Matthew Wallingford, Vivek Ramanujan, Alex Fang, Aditya Kusupati, Roozbeh Mottaghi, Aniruddha Kembhavi, Ludwig Schmidt, Ali Farhadi
* `NeurIPS-2023` **[ChatGPT-Powered Hierarchical Comparisons for Image Classification](https://proceedings.neurips.cc/paper_files/paper/2023/file/dc81297c791bb989deade65c6bd8c1d8-Paper-Conference.pdf)** [![Star](https://img.shields.io/github/stars/Zhiyuan-R/ChatGPT-Powered-Hierarchical-Comparisons-for-Image-Classification.svg?style=social&label=Star)](https://github.com/Zhiyuan-R/ChatGPT-Powered-Hierarchical-Comparisons-for-Image-Classification)
    * Zhiyuan Ren, Yiyang Su, Xiaoming Liu
* `EMNLP-2023` **[Prompting Scientific Names for Zero-Shot Species Recognition](https://aclanthology.org/2023.emnlp-main.610.pdf)**
    * Shubham Parashar, Zhiqiu Lin, Yanan Li, Shu Kong
* `arXiv 2023` **[TAP: Targeted Prompting for Task Adaptive Generation of Textual Training Instances for Visual Classification](https://arxiv.org/pdf/2309.06809)** [![Star](https://img.shields.io/github/stars/jmiemirza/TAP.svg?style=social&label=Star)](https://github.com/jmiemirza/TAP)
    * M Jehanzeb Mirza, Leonid Karlinsky, Wei Lin, Horst Possegger, Rogerio Feris, Horst Bischof
* `CVPR-2024` **[Grounding Everything: Emerging Localization Properties in Vision-Language Transformers](https://openaccess.thecvf.com/content/CVPR2024/papers/Bousselham_Grounding_Everything_Emerging_Localization_Properties_in_Vision-Language_Transformers_CVPR_2024_paper.pdf)** [![Star](https://img.shields.io/github/stars/WalBouss/GEM.svg?style=social&label=Star)](https://github.com/WalBouss/GEM)
    * Walid Bousselham, Felix Petersen, Vittorio Ferrari, Hilde Kuehne
* `CVPR-2024` **[The Neglected Tails in Vision-Language Models](https://openaccess.thecvf.com/content/CVPR2024/papers/Parashar_The_Neglected_Tails_in_Vision-Language_Models_CVPR_2024_paper.pdf)** [![Star](https://img.shields.io/github/stars/shubhamprshr27/NeglectedTailsVLM.svg?style=social&label=Star)](https://github.com/shubhamprshr27/NeglectedTailsVLM)
    * Shubham Parashar, Zhiqiu Lin, Tian Liu, Xiangjue Dong, Yanan Li, Deva Ramanan, James Caverlee, Shu Kong
* `ICML-2024` **[Envisioning Outlier Exposure by Large Language Models for Out-of-Distribution Detection](https://arxiv.org/pdf/2406.00806)** [![Star](https://img.shields.io/github/stars/tmlr-group/EOE.svg?style=social&label=Star)](https://github.com/tmlr-group/EOE)
    * Chentao Cao, Zhun Zhong, Zhanke Zhou, Yang Liu, Tongliang Liu, Bo Han
* `ECCV-2024` **[Meta-Prompting for Automating Zero-shot Visual Recognition with LLMs](https://arxiv.org/pdf/2403.11755)** [![Star](https://img.shields.io/github/stars/jmiemirza/Meta-Prompting.svg?style=social&label=Star)](https://github.com/jmiemirza/Meta-Prompting)
    * M Jehanzeb Mirza, Leonid Karlinsky, Wei Lin, Sivan Doveh, Jakub Micorek, Mateusz Kozinski, Hilde Kuehne, Horst Possegger
* `ECCV-2024` **[SCLIP: Rethinking Self-Attention for Dense Vision-Language Inference](https://arxiv.org/pdf/2312.01597)** [![Star](https://img.shields.io/github/stars/wangf3014/SCLIP.svg?style=social&label=Star)](https://github.com/wangf3014/SCLIP)
    * Feng Wang, Jieru Mei, Alan Yuille
* `ECCV-2024` **[ClearCLIP: Decomposing CLIP Representations for Dense Vision-Language Inference](https://arxiv.org/pdf/2407.12442)** [![Star](https://img.shields.io/github/stars/mc-lan/ClearCLIP.svg?style=social&label=Star)](https://github.com/mc-lan/ClearCLIP)
    * Mengcheng Lan, Chaofeng Chen, Yiping Ke, Xinjiang Wang, Litong Feng, Wayne Zhang
* `ECCV-2024` **[ProxyCLIP: Proxy Attention Improves CLIP for Open-Vocabulary Segmentation](https://arxiv.org/pdf/2408.04883)** [![Star](https://img.shields.io/github/stars/mc-lan/ProxyCLIP.svg?style=social&label=Star)](https://github.com/mc-lan/ProxyCLIP)
    * Mengcheng Lan, Chaofeng Chen, Yiping Ke, Xinjiang Wang, Litong Feng, Wayne Zhang
* `ECCV-2024` **[TAG: Text Prompt Augmentation for Zero-Shot Out-of-Distribution Detection](https://openreview.net/pdf?id=ghJXIRlKat#page=7.41)** [![Star](https://img.shields.io/github/stars/XixiLiu95/TAG.svg?style=social&label=Star)](https://github.com/XixiLiu95/TAG)
    * Xixi Liu, Christopher Zach
* `ICPR-2024` **[Text-Enhanced Zero-Shot Action Recognition: A Training-Free Approach](https://arxiv.org/pdf/2408.16412)** [![Star](https://img.shields.io/github/stars/MaXDL4Phys/tear.svg?style=social&label=Star)](https://github.com/MaXDL4Phys/tear)
    * Massimo Bosetti, Shibingfeng Zhang, Bendetta Liberatori, Giacomo Zara, Elisa Ricci, Paolo Rota
* `ACMFAccT-2024` **[Embracing Diversity: Interpretable Zero-shot Classification Beyond One Vector Per Class](https://dl.acm.org/doi/pdf/10.1145/3630106.3659039)**
    * Mazda Moayeri, Michael Rabbat, Mark Ibrahim, Diane Bouchacourt
* `arXiv 2024` **[Training-Free Semantic Segmentation via LLM-Supervision](https://arxiv.org/pdf/2404.00701)**
    * Wenfang Sun, Yingjun Du, Gaowen Liu, Ramana Kompella, Cees GM Snoek
* `arXiv 2024` **[Just Say the Name: Online Continual Learning with Category Names Only via Data Generation](https://arxiv.org/pdf/2403.10853)**
    * Minhyuk Seo, Seongwon Cho, Minjae Lee, Diganta Misra, Hyeonbeom Choi, Seon Joo Kim, Jonghyun Choi
* `WACV-2025` **[Pay Attention to Your Neighbours: Training-Free Open-Vocabulary Semantic Segmentation](https://arxiv.org/pdf/2404.08181)** [![Star](https://img.shields.io/github/stars/sinahmr/NACLIP.svg?style=social&label=Star)](https://github.com/sinahmr/NACLIP)
    * Sina Hajimiri, Ismail Ben Ayed, Jose Dolz
* `WACV-2025` **[Enhancing Visual Classification using Comparative Descriptors](https://arxiv.org/pdf/2411.05357)** [![Star](https://img.shields.io/github/stars/hk1ee/Comparative-CLIP.svg?style=social&label=Star)](https://github.com/hk1ee/Comparative-CLIP)
    * Hankyeol Lee, Gawon Seo, Wonseok Choi, Geunyoung Jung, Kyungwoo Song, Jiyoung Jung
* `AAAI-2025` **[Learning to Prompt with Text Only Supervision for Vision-Language Models](https://arxiv.org/pdf/2401.02418)** [![Star](https://img.shields.io/github/stars/muzairkhattak/ProText.svg?style=social&label=Star)](https://github.com/muzairkhattak/ProText)
    * Muhammad Uzair Khattak, Muhammad Ferjad Naeem, Muzammal Naseer, Luc Van Gool, Federico Tombari
* `ICME-2025` **[Attributed Synthetic Data Generation for Zero-shot Domain-specific Image Classification](https://arxiv.org/pdf/2504.04510)**
    * Shijian Wang, Linxin Song, Ryotaro Shimizu, Masayuki Goto, Hanqian Wu
* `PR-2025` **[A Closer Look at the Explainability of Contrastive Language-Image Pre-training](https://arxiv.org/pdf/2304.05653)** [![Star](https://img.shields.io/github/stars/xmed-lab/CLIP_Surgery.svg?style=social&label=Star)](https://github.com/xmed-lab/CLIP_Surgery)
    * Yi Li, Hualiang Wang, Yiqun Duan, Jiheng Zhang, Xiaomeng Li
* `arXiv 2025` **[Making Better Mistakes in CLIP-based Zero-Shot Classification with Hierarchy-Aware Language Prompts](https://arxiv.org/pdf/2503.02248)** [![Star](https://img.shields.io/github/stars/ltong1130ztr/HAPrompts.svg?style=social&label=Star)](https://github.com/ltong1130ztr/HAPrompts)
    * Tong Liang, Jim Davis
