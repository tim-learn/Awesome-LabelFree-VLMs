# Online Test-Time Adaptation

* `NeurIPS-2023` **[SwapPrompt: Test-Time Prompt Adaptation for Vision-Language Models](https://openreview.net/pdf?id=EhdNQiOWgQ)**
    * Xiaosong Ma, Jie Zhang, Song Guo, Wenchao Xu
* `NeurIPS-2023` **[Test-Time Distribution Normalization for Contrastively Learned Vision-language Models](https://arxiv.org/pdf/2302.11084)** [![Star](https://img.shields.io/github/stars/fengyuli-dev/distribution-normalization.svg?style=social&label=Star)](https://github.com/fengyuli-dev/distribution-normalization)
    * Yifei Zhou, Juntao Ren, Fengyu Li, Ramin Zabih, Ser-Nam Lim
* `AAAI-2024` **[Robust Test-Time Adaptation for Zero-Shot Prompt Tuning](https://ojs.aaai.org/index.php/AAAI/article/view/29611/31034)**
    * Ding-Chu Zhang, Zhi Zhou, Yu-Feng Li
* `AAAI-2024` **[DART: Dual-Modal Adaptive Online Prompting and Knowledge Retention for Test-Time Adaptation](https://ojs.aaai.org/index.php/AAAI/article/view/29320/30490)** [![Star](https://img.shields.io/github/stars/zhoujiahuan1991/AAAI2024-DART.svg?style=social&label=Star)](https://github.com/zhoujiahuan1991/AAAI2024-DART)
    * Zichen Liu, Hongbo Sun, Yuxin Peng, Jiahuan Zhou
* `CVPR-2024` **[Efficient Test-Time Adaptation of Vision-Language Models](https://arxiv.org/pdf/2403.18293)** [![Star](https://img.shields.io/github/stars/kdiAAA/TDA.svg?style=social&label=Star)](https://github.com/kdiAAA/TDA)
    * Adilbek Karmanov, Dayan Guan, Shijian Lu, Abdulmotaleb El Saddik, Eric Xing
* `CVPR-2024` **[Dual Memory Networks: A Versatile Adaptation Approach for Vision-Language Models](https://arxiv.org/pdf/2403.17589)** [![Star](https://img.shields.io/github/stars/YBZh/DMN.svg?style=social&label=Star)](https://github.com/YBZh/DMN)
    * Yabin Zhang, Wenjie Zhu, Hui Tang, Zhiyuan Ma, Kaiyang Zhou, Lei Zhang
* `CVPR-2024` **[Improved Self-Training for Test-Time Adaptation](https://openaccess.thecvf.com/content/CVPR2024/papers/Ma_Improved_Self-Training_for_Test-Time_Adaptation_CVPR_2024_paper.pdf)**
    * Jing Ma
* `CVPR-2024` **[Any-Shift Prompting for Generalization over Distributions](https://arxiv.org/pdf/2402.10099)**
    * Zehao Xiao, Jiayi Shen, Mohammad Mahdi Derakhshani, Shengcai Liao, Cees G. M. Snoek
* `IJCNN-2024` **[Prompt-based Memory Bank for Continual Test-Time Domain Adaptation in Vision-Language Models](https://ieeexplore.ieee.org/document/10650069)**
    * Ran Wang, Hua Zuo, Zhen Fang, Jie Lu
* `ECCV-2024` **[Online Zero-Shot Classification with CLIP](https://arxiv.org/pdf/2408.13320)** [![Star](https://img.shields.io/github/stars/idstcv/OnZeta.svg?style=social&label=Star)](https://github.com/idstcv/OnZeta)
    * Qi Qian, Juhua Hu
* `ECCVW-2024` **[A Lost Opportunity for Vision-Language Models: A Comparative Study of Online Test-Time Adaptation for Vision-Language Models](https://arxiv.org/pdf/2405.14977)** [![Star](https://img.shields.io/github/stars/mariodoebler/test-time-adaptation.svg?style=social&label=Star)](https://github.com/mariodoebler/test-time-adaptation)
    * Mario Döbler, Robert A. Marsden, Tobias Raichle, Bin Yang
* `ACMMM-2024` **[Towards Robustness Prompt Tuning with Fully Test-Time Adaptation for CLIP’s Zero-Shot Generalization](https://dl.acm.org/doi/pdf/10.1145/3664647.3681213)**
    * Ran Wang, Hua Zuo, Zhen Fang, Jie Lu
* `NeurIPS-2024` **[WATT: Weight Average Test-Time Adaptation of CLIP](https://arxiv.org/pdf/2406.13875)** [![Star](https://img.shields.io/github/stars/Mehrdad-Noori/WATT.svg?style=social&label=Star)](https://github.com/Mehrdad-Noori/WATT)
    * David Osowiechi, Mehrdad Noori, Gustavo Adolfo Vargas Hakim, Moslem Yazdanpanah, Ali Bahri, Milad Cheraghalikhani, Sahar Dastani, Farzad Beizaee, Ismail Ben Ayed, Christian Desrosiers
* `NeurIPS-2024` **[Dual Prototype Evolving for Test-Time Generalization of Vision-Language Models](https://arxiv.org/pdf/2410.12790)** [![Star](https://img.shields.io/github/stars/zhangce01/DPE-CLIP.svg?style=social&label=Star)](https://github.com/zhangce01/DPE-CLIP)
    * Ce Zhang, Simon Stepputtis, Katia Sycara, Yaqi Xie
* `NeurIPS-2024` **[BoostAdapter: Improving Vision-Language Test-Time Adaptation via Regional Bootstrapping](https://arxiv.org/pdf/2410.15430)** [![Star](https://img.shields.io/github/stars/taolinzhang/BoostAdapter.svg?style=social&label=Star)](https://github.com/taolinzhang/BoostAdapter)
    * Taolin Zhang, Jinpeng Wang, Hang Guo, Tao Dai, Bin Chen, Shu-Tao Xia
* `NeurIPS-2024` **[Historical Test-time Prompt Tuning for Vision Foundation Models](https://arxiv.org/pdf/2410.20346)**
    * Jingyi Zhang, Jiaxing Huang, Xiaoqin Zhang, Ling Shao, Shijian Lu
* `BIBM-2024` **[Test-Time Medical Image Segmentation Using CLIP-Guided SAM Adaptation](https://ieeexplore.ieee.org/document/10822570)**
    * Haotian Chen, Yonghui Xu, Yanyu Xu, Yixin Zhang, Lizhen Cui
* `arXiv 2024` **[DOTA: Distributional Test-Time Adaptation of Vision-Language Model](https://arxiv.org/pdf/2409.19375)**
    * Zongbo Han, Jialong Yang, Junfan Li, Qinghua Hu, Qianli Xu, Mike Zheng Shou, Changqing Zhang
* `arXiv 2024` **[Test-time Alignment-Enhanced Adapter for Vision-Language Models](https://arxiv.org/pdf/2411.15735)**
    * Baoshun Tong, Kaiyu Song, Hanjiang Lai
* `arXiv 2024` **[BaFTA: Backprop-Free Test-Time Adaptation For Zero-Shot Vision-Language Models](https://arxiv.org/pdf/2406.11309)**
    * Xuefeng Hu, Ke Zhang, Min Sun, Albert Chen, Cheng-Hao Kuo, Ram Nevatia
* `arXiv 2024` **[Words Matter: Leveraging Individual Text Embeddings for Code Generation in CLIP Test-Time Adaptation](https://arxiv.org/pdf/2411.17002)**
    * Shambhavi Mishra, Julio Silva-Rodrıguez, Ismail Ben Ayed, Marco Pedersoli, Jose Dolz
* `arXiv 2024` **[Beyond Model Adaptation at Test Time: A Survey](https://arxiv.org/pdf/2411.03687)** [![Star](https://img.shields.io/github/stars/zzzx1224/Beyond-model-adaptation-at-test-time-Papers.svg?style=social&label=Star)](https://github.com/zzzx1224/Beyond-model-adaptation-at-test-time-Papers)
    * Zehao Xiao, Cees G. M. Snoek
* `WACV-2025` **[CLIPArTT: Adaptation of CLIP to New Domains at Test Time](https://arxiv.org/pdf/2405.00754)** [![Star](https://img.shields.io/github/stars/dosowiechi/CLIPArTT.svg?style=social&label=Star)](https://github.com/dosowiechi/CLIPArTT)
    * Gustavo Adolfo Vargas Hakim, David Osowiechi, Mehrdad Noori, Milad Cheraghalikhani, Ali Bahri, Moslem Yazdanpanah, Ismail Ben Ayed, Christian Desrosiers
* `ICLR-2025` **[Noisy Test-Time Adaptation in Vision-Language Models](https://openreview.net/pdf?id=iylpeTI0Ql)** [![Star](https://img.shields.io/github/stars/tmlr-group/ZS-NTTA.svg?style=social&label=Star)](https://github.com/tmlr-group/ZS-NTTA)
    * Chentao Cao, Zhun Zhong, Zhanke Zhou, Tongliang Liu, Yang Liu, Kun Zhang, Bo Han
* `ICLR-2025` **[Efficient and Context-Aware Label Propagation for Zero-/Few-Shot Training-Free Adaptation of Vision-Language Model](https://openreview.net/pdf?id=D10yarGQNk)** [![Star](https://img.shields.io/github/stars/Yushu-Li/ECALP.svg?style=social&label=Star)](https://github.com/Yushu-Li/ECALP)
    * Yushu Li, Yongyi Su, Adam Goodge, Kui Jia, Xun Xu
* `ICLR-2025` **[DynaPrompt: Dynamic Test-Time Prompt Tuning](https://openreview.net/pdf?id=EFZEdHB3Mp)** [![Star](https://img.shields.io/github/stars/zzzx1224/DynaPrompt.svg?style=social&label=Star)](https://github.com/zzzx1224/DynaPrompt)
    * Zehao Xiao, Shilin Yan, Jack Hong, Jiayin Cai, Xiaolong Jiang, Yao Hu, Jiayi Shen, Cheems Wang, Cees G. M. Snoek
* `ICLR-2025` **[Test-time Adaptation for Cross-modal Retrieval with Query Shift](https://openreview.net/pdf?id=BmG88rONaU)** [![Star](https://img.shields.io/github/stars/XLearning-SCU/2025-ICLR-TCR.svg?style=social&label=Star)](https://github.com/XLearning-SCU/2025-ICLR-TCR)
    * Haobin Li, Peng Hu, Qianjun Zhang, Xi Peng, XitingLiu, Mouxing Yang
* `ICLRW-2025` **[Mitigating Cache Noise in Test-Time Adaptation for Large Vision-Language Models](https://arxiv.org/pdf/2503.18334)**
    * Haotian Zhai, Xinyu Chen, Can Zhang, Tianming Sha, Ruirui Li
* `CVPR-2025` **[Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM](https://arxiv.org/pdf/2507.06973)**
    * Qiyuan Dai, Sibei Yang
* `CVPR-2025` **[Bayesian Test-Time Adaptation for Vision-Language Models](https://arxiv.org/pdf/2503.09248)**
    * Lihua Zhou, Mao Ye, Shuaifeng Li, Nianxin Li, Xiatian Zhu, Lei Deng, Hongbin Liu, Zhen Lei
* `CVPR-2025` **[COSMIC: Clique-Oriented Semantic Multi-space Integration for Robust CLIP Test-Time Adaptation](https://arxiv.org/pdf/2503.23388)** [![Star](https://img.shields.io/github/stars/hf618/COSMIC.svg?style=social&label=Star)](https://github.com/hf618/COSMIC)
    * Fanding Huang, Jingyan Jiang, Qinting Jiang, Hebei Li, Faisal Nadeem Khan, Zhi Wang
* `CVPR-2025` **[Hierarchical Knowledge Prompt Tuning for Multi-task Test-Time Adaptation](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Hierarchical_Knowledge_Prompt_Tuning_for_Multi-task_Test-Time_Adaptation_CVPR_2025_paper.pdf)**
    * Qiang Zhang, Mengsheng Zhao, Jiawei Liu, Fanrui Zhang, Yongchao Xu, Zheng-Jun Zha
* `CVPR-2025` **[On the Zero-shot Adversarial Robustness of Vision-Language Models: A Truly Zero-shot and Training-free Approach](https://openaccess.thecvf.com/content/CVPR2025/papers/Tong_On_the_Zero-shot_Adversarial_Robustness_of_Vision-Language_Models_A_Truly_CVPR_2025_paper.pdf)**
    * Baoshun Tong, Hanjiang Lai, Yan Pan, Jian Yin
* `ICCV-2025` **[BATCLIP: Bimodal Online Test-Time Adaptation for CLIP](https://arxiv.org/pdf/2412.02837)** [![Star](https://img.shields.io/github/stars/sarthaxxxxx/BATCLIP.svg?style=social&label=Star)](https://github.com/sarthaxxxxx/BATCLIP)
    * Sarthak Kumar Maharana, Baoming Zhang, Leonid Karlinsky, Rogerio Feris, Yunhui Guo
* `ICCV-2025` **[Is Less More? Exploring Token Condensation as Training-free Test-time Adaptation](https://arxiv.org/pdf/2410.14729)**
    * Zixin Wang, Dong Gong, Sen Wang, Zi Huang, Yadan Luo
* `TMLR-2025` **[Effectiveness of Vision Language Models for Open-world Single Image Test Time Adaptation](https://arxiv.org/pdf/2406.00481)** [![Star](https://img.shields.io/github/stars/manogna-s/ROSITA.svg?style=social&label=Star)](https://github.com/manogna-s/ROSITA)
    * Manogna Sreenivas, Soma Biswas
* `TIP-2025` **[Task-to-Instance Prompt Learning for Vision-Language Models at Test Time](https://ieeexplore.ieee.org/document/10925517)** [![Star](https://img.shields.io/github/stars/zhiheLu/TIPPLE.svg?style=social&label=Star)](https://github.com/zhiheLu/TIPPLE)
    * Jiawang Bai, Zhihe Lu, Xin Li, Zeyu Xiao, Xinchao Wang
* `PR-2025` **[CTPT: Continual Test-time Prompt Tuning for Vision-Language Models](https://www.sciencedirect.com/science/article/pii/S0031320324010513)**
    * Fan Wang, Zhongyi Han, Xingbo Liu, Yilong Yin, Xin Gao
* `arXiv 2025` **[Online Gaussian Test-Time Adaptation of Vision-Language Models](https://arxiv.org/pdf/2501.04352)** [![Star](https://img.shields.io/github/stars/cfuchs2023/OGA.svg?style=social&label=Star)](https://github.com/cfuchs2023/OGA)
    * Clément Fuchs, Maxime Zanella, Christophe De Vleeschouwer
* `arXiv 2025` **[Space Rotation with Basis Transformation for Training-free Test-Time Adaptation](https://arxiv.org/pdf/2502.19946)**
    * Chenhao Ding, Xinyuan Gao, Songlin Dong, Yuhang He, Qiang Wang, Xiang Song, Alex Kot, Yihong Gong
* `arXiv 2025` **[TEST-V: TEst-time Support-set Tuning for Zero-shot Video Classification](https://arxiv.org/pdf/2502.00426)**
    * Rui Yan, Jin Wang, Hongyu Qu, Xiaoyu Du, Dong Zhang, Jinhui Tang, Tieniu Tan
* `arXiv 2025` **[Uniformity First: Uniformity-aware Test-time Adaptation of Vision-language Models against Image Corruption](https://arxiv.org/pdf/2505.12912)**
    * Kazuki Adachi, Shin'ya Yamaguchi, Tomoki Hamagami
* `arXiv 2025` **[Small Aid, Big Leap: Efficient Test-Time Adaptation for Vision-Language Models with AdaptNet](https://arxiv.org/pdf/2506.02671)**
    * Xiao Chen, Jiazhen Huang, Qinting Jiang, Fanding Huang, Xianghua Fu, Jingyan Jiang, Zhi Wang
* `arXiv 2025` **[MINT: Memory-Infused Prompt Tuning at Test-time for CLIP](https://arxiv.org/pdf/2506.03190)**
    * Jiaming Yi, Ruirui Pan, Jishen Yang, Xiulong Yang
* `arXiv 2025` **[BayesTTA: Continual-Temporal Test-Time Adaptation for Vision-Language Models via Gaussian Discriminant Analysis](https://arxiv.org/pdf/2507.08607)** [![Star](https://img.shields.io/github/stars/cuishuang99/BayesTTA.svg?style=social&label=Star)](https://github.com/cuishuang99/BayesTTA)
    * Shuang Cui, Jinglin Xu, Yi Li, Xiongxin Tang, Jiangmeng Li, Jiahuan Zhou, Fanjiang Xu, Fuchun Sun, Hui Xiong
* `arXiv 2025` **[CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation](https://arxiv.org/pdf/2507.14312)**
    * Marc Lafon, Gustavo Adolfo Vargas Hakim, Clément Rambour, Christian Desrosier, Nicolas Thome
* `arXiv 2025` **[Negation-Aware Test-Time Adaptation for Vision-Language Models](https://arxiv.org/pdf/2507.19064)** [![Star](https://img.shields.io/github/stars/hhc1997/NEAT.svg?style=social&label=Star)](https://github.com/hhc1997/NEAT)
    * Haochen Han, Alex Jinpeng Wang, Fangming Liu
* `Openreview 2025` **[Active Test Time Prompt Learning in Vision-Language Models](https://openreview.net/pdf?id=pdzHpQbGrn)**
    * Dhruv Sarkar, Aprameyo Chakrabartty, Bibhudatta Bhanja, Abir Das
